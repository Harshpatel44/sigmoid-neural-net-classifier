{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled4.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJUW1V5Yi4ke",
        "colab_type": "text"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-E12obAG2Gv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import figure\n",
        "import numpy as np\n",
        "from numpy.random import default_rng\n",
        "import time\n",
        "rng = default_rng()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4G-4pMNixI0",
        "colab_type": "text"
      },
      "source": [
        "# Creating clusters dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3dT4HK5GjBz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Weights\n",
        "np.random.seed(0)\n",
        "class data_set1:\n",
        "  def __init__(self):\n",
        "    self.cov1= [[0,0],[0,0]]  #covariance for class1\n",
        "    self.cov2=[[0,0],[0,0]]   #covariance for class2   \n",
        "    \n",
        "    # method to adjust noise\n",
        "  def noise(self,amt1,amt2=0):             \n",
        "    n1=(3.5 - 0.4)*(amt1) + 0.4  #3.5 is max covariance and 0.4 is min covariance taken for noise\n",
        "    self.cov1=[[n1,0],[0,n1]]\n",
        "    if(amt2==0):\n",
        "      amt2=amt1\n",
        "    n2=(3.5 - 0.4)*(amt2) + 0.4\n",
        "    self.cov2=[[n2,0],[0,n2]]\n",
        "  #method to create data\n",
        "  def create(self,n=2,items=100,noise=0):\n",
        "    self.noise(noise,noise)\n",
        "    self.n= n\n",
        "    \n",
        "    self.items= int(np.round(items/n))    # items per class =  all items / n \n",
        "    mx = rng.choice(int(self.n), size=self.n, replace=False)  # random x value of mean \n",
        "    my = rng.choice(int(self.n), size=self.n, replace=False)  # random y value of mean\n",
        "    for i in range(self.n):\n",
        "        if(i==0):\n",
        "          x1, y1 = np.random.multivariate_normal([mx[i]*3,my[i]*2], self.cov1, self.items).T  #class1\n",
        "          self.d1_data = np.array([x1,y1,np.zeros(x1.shape)+i])\n",
        "        else:\n",
        "          x2, y2 = np.random.multivariate_normal([mx[i]*3,my[i]*2], self.cov2, self.items).T  #class2\n",
        "          self.d1_data=np.append(self.d1_data,[x2,y2,np.zeros(x1.shape)+i],axis=1)\n",
        "          \n",
        "    #appending both classes to 1 array and also adding another column of labels\n",
        "    self.d1_data=self.d1_data.T\n",
        "    return self.d1_data\n",
        "  def plot(self):\n",
        "    plt.figure(figsize=(5,5))\n",
        "    plt.scatter(self.d1_data[:,0],self.d1_data[:,1],c=self.d1_data[:,2])\n",
        "    ax = plt.gca()\n",
        "    ax.set_facecolor('xkcd:salmon')\n",
        "    ax.set_facecolor((0, 0, 0))\n",
        "    plt.show()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RqFmOmoDjFNv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "outputId": "86ed04cd-829b-4def-9b0f-f293198299c7"
      },
      "source": [
        "obj1=data_set1()\n",
        "dataset=obj1.create(2,10,0.00)   #class,items,noise\n",
        "np.random.shuffle(dataset)\n",
        "obj1.plot()"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXCcSkLRtv81",
        "colab_type": "text"
      },
      "source": [
        "# Training and testing model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXxa6izZG9Ph",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model:\n",
        "    def __init__(self,X_train,y_train):\n",
        "        self.lossList=[]\n",
        "        self.y_train=y_train\n",
        "        self.X_train=X_train\n",
        "\n",
        "    def sigmoid(self,x):\n",
        "        return 1/(1+np.exp(-x))\n",
        "\n",
        "    def sigmoidDerivation(self,x):\n",
        "        return x * (1 - x)\n",
        "    def lossFunction(self,y,t):\n",
        "        return np.mean(np.power(y - t,2))\n",
        "\n",
        "    def trainModel(self,learningRate,iterations,phase='train'):\n",
        "        self.learningRate = learningRate\n",
        "        self.iterations=iterations\n",
        "        self.w0 = 2*np.random.random((2, 5)) - 1 #for input   - 4 inputs, 3 outputs\n",
        "        self.w1 = 2*np.random.random((5, 1)) - 1 #for layer 1 - 5 inputs, 3 outputs\n",
        "\n",
        "        for i in range(self.iterations):\n",
        "            #Feedforward propagation\n",
        "            layer0 = self.X_train\n",
        "            layer1 = self.sigmoid(np.dot(layer0, self.w0))\n",
        "            layer2 = self.sigmoid(np.dot(layer1, self.w1))\n",
        "            loss=self.lossFunction(layer2,self.y_train)\n",
        "\n",
        "            #Backpropagation \n",
        "            layer2_error =  self.y_train - layer2\n",
        "            layer2_delta = layer2_error * self.sigmoidDerivation(layer2)\n",
        "            layer1_error = layer2_delta.dot(self.w1.T)\n",
        "            layer1_delta = layer2_delta * self.sigmoidDerivation(layer1)\n",
        "            \n",
        "            #updating gradients\n",
        "            self.w1 += -layer1.T.dot(layer2_delta) * self.learningRate\n",
        "            self.w0 += -layer0.T.dot(layer1_delta) * self.learningRate\n",
        "            \n",
        "            #append loss\n",
        "            self.lossList.append(loss)\n",
        "        if(phase=='test'):\n",
        "            return self.lossList,layer2\n",
        "        return self.lossList\n",
        "    # def testModel(self,data,output):\n",
        "    #     loss,layer2=self.trainModel(self.learningRate,1,'test')\n",
        "    #     print(np.mean(layer2-output))\n",
        "    #     return accuracy\n",
        "\n",
        "    def plot(self,loss):\n",
        "        #Plot the accuracy chart\n",
        "        plt.plot(loss)\n",
        "        plt.xlabel('Training')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0lFDsjYklFR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "outputId": "33e2fc7e-5967-43ca-f9a4-5e577fa02da2"
      },
      "source": [
        "inputData=dataset[:,:-1]\n",
        "label=dataset[:,-1]\n",
        "label=label.reshape(label.shape[0],1)\n",
        "\n",
        "model=Model(inputData,label)\n",
        "loss=model.trainModel(0.1,100)\n",
        "trainingAccuracy=model.testModel(inputData,label)\n",
        "model.plot(loss)\n",
        "print(\"Training Accuracy \" + str(round(trainingAccuracy,2)) + \"%\")"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-0.043539607890393774\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-116-d1d2cd1d283d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputData\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtrainingAccuracy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtestModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputData\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training Accuracy \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainingAccuracy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"%\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-115-af3bc735ce7b>\u001b[0m in \u001b[0;36mtestModel\u001b[0;34m(self, data, output)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearningRate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'accuracy' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6KjNJ3SnJbd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}